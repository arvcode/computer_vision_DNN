{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Shot Learning with Cosine Similarity\n",
    "This notebook contains code for Face recognition.\n",
    "\n",
    "Reference:\n",
    "\n",
    "https://sefiks.com/2018/08/06/deep-face-recognition-with-keras/\n",
    "\n",
    "https://www.robots.ox.ac.uk/~vgg/data/vgg_face/\n",
    "\n",
    "Udemy Course:\n",
    "\n",
    "https://www.udemy.com/share/10381KBEoacl5STXU=/\n",
    "\n",
    "\n",
    "Note:\n",
    "Please put the person images in people_images folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules.\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import load_img, save_img, img_to_array\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "#VGG 16 CNN model.\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2 as cv\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGGFace.\n",
    "#https://www.robots.ox.ac.uk/~vgg/\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(2622, (1, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))\n",
    "#print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model.\n",
    "# Download the model from https://drive.google.com/file/d/1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo/view?usp=sharing\n",
    "#plot_model(model, to_file='VGG-16.png')\n",
    "model.load_weights('models/vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to pre-process images\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find Cosine Similarity.\n",
    "\n",
    "def cosine_similarity(src_vector, test_vector):\n",
    "    #Cosine Distance\n",
    "    num=np.matmul(np.transpose(src_vector),test_vector)\n",
    "    norm1=np.sum(np.multiply(src_vector,src_vector))\n",
    "    norm2=np.sum(np.multiply(test_vector,test_vector))\n",
    "    return 1 -(num/(np.sqrt(norm1)*np.sqrt(norm2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previous layer from output.\n",
    "vgg_face_descriptor= Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 5 images\n",
      "Found a face\n",
      "Found a face\n",
      "Found a face\n",
      "Found a face\n",
      "Found a face\n"
     ]
    }
   ],
   "source": [
    "#Detect faces via camera.\n",
    "\n",
    "#Find faces from images and save them.\n",
    "def makedir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        return None\n",
    "    else:\n",
    "        pass\n",
    "#Haar Cascade Classifier.\n",
    "\n",
    "face_detector=cv.CascadeClassifier('Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "mypath = \"./people_images/\"\n",
    "image_file_names = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "print(\"Collected \" + str(len(image_file_names)) + \" images\")\n",
    "makedir(\"./faces/\")\n",
    "\n",
    "for image_name in image_file_names:\n",
    "    person_image = cv.imread(mypath+image_name)\n",
    "    face_info = face_detector.detectMultiScale(person_image, 1.3, 5)\n",
    "    print('Found a face')\n",
    "    for (x,y,w,h) in face_info:\n",
    "        face = person_image[y:y+h, x:x+w]\n",
    "        roi = cv.resize(face, (128, 128), interpolation = cv.INTER_CUBIC)\n",
    "        path = \"./faces/\" + \"face_\" + image_name \n",
    "        cv.imwrite(path, roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_folder='./faces'\n",
    "#Dictionary to store feature vectors.\n",
    "face_dict=dict()\n",
    "\n",
    "for file in listdir(face_folder):\n",
    "    person,ext=file.split(\".\")\n",
    "    face_dict[person]=vgg_face_descriptor.predict(preprocess_image('./faces/%s.jpg' % (person)))[0,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture=cv.VideoCapture(0)\n",
    "\n",
    "while (True):\n",
    "    ret, img=capture.read()\n",
    "    #Haar Cascade Classifier\n",
    "    faces=face_detector.detectMultiScale(img,1.3,5)\n",
    "  \n",
    "    for (x,y,w,h) in faces:\n",
    "        if w >100:\n",
    "            #Draw bounding rectangle.\n",
    "            cv.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "            #Crop the image.\n",
    "            face_detect=img[int(y):int(y+h),int(x):int(x+w)]\n",
    "            #Resize to VGGFace dimensions.\n",
    "            face_detect=cv.resize(face_detect,(224,224))\n",
    "            #PreProcess image.\n",
    "\n",
    "\n",
    "            img_pixels = image.img_to_array(face_detect)\n",
    "            img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "            img_pixels /= 255\n",
    "            #face_detect=preprocess_image(face_detect)\n",
    "            #face_detect/=255\n",
    "            #cv.imshow('Image',img)\n",
    "            capture_vector=vgg_face_descriptor.predict(img_pixels)[0,:]\n",
    "            found=0\n",
    "            for index in face_dict:\n",
    "                saved_vector=face_dict[index]\n",
    "                name=index\n",
    "                cs=cosine_similarity(capture_vector,saved_vector)\n",
    "                if (cs<0.45):\n",
    "                    cv.putText(img, name[5:], (int(x+w+15), int(y-12)), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                    found=1\n",
    "                    #cv.rectangle(img,(x,y),(x+w,y+h),(255,0,255),2)\n",
    "                    break\n",
    "                    #connect face and text\n",
    "                cv.line(img,(int((x+x+w)/2),y+15),(x+w,y-20),(255, 0, 0),1)\n",
    "                cv.line(img,(x+w,y-20),(x+w+10,y-20),(255, 0, 0),1)\n",
    "\n",
    "                if(found == 0): #if found image is not in our people database\n",
    "                    cv.putText(img, 'unknown', (int(x+w+15), int(y-12)), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    cv.imshow('Image',img)\n",
    "    if cv.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "capture.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
